# -*- coding: utf-8 -*-
"""TF-IDF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LXaEcqD8RdnfyijQRxJj9ypDLvONry7s
"""

import pandas as pd

!mkdir ~/.kaggle

!cp /content/kaggle.json /root/.kaggle

!chmod 600 /root/.kaggle/kaggle.json

import os
os.environ["KAGGLE_CONFIG_"] =' /content/kaggle.json'

!kaggle competitions download -c quora-question-pairs

!unzip /content/quora-question-pairs.zip

!unzip /content/train.csv.zip

df = pd.read_csv('/content/train.csv')
df.head()

df.isnull().sum()

df.dropna()

df.drop(['id', 'qid1', 'qid2'], axis=1, inplace=True)
a = 0 
for i in range(a,a+10):
    print(df.question1[i])
    print(df.question2[i])
    print()

# def preprocessing(data):# mode=train or eval

#   def cleanHtml(sentence):
#     cleanr = re.compile('<.*?>')
#     cleantxt = re.sub(cleanr, ' ', sentence)
#     return cleantxt

#   def cleanpunc(sentence):
#     cleaned = re.sub(r'[?|!|\'|"|#]', r'', sentence)
#     cleaned = re.sub(r'[.|,|)|(|\|/]', r' ', cleaned)
#     return cleaned
#   sno = nltk.stem.SnowballStemmer("english")
#   stop = set(stopwords.words("english"))
#   str1 = ''
#   i = 0
#   for string in data:
#     filtered_sentence = []
#     # Removes html tags from every review
#     sent = cleanHtml(string)
#     for w in sent.split():
#         # For every word in a review clean punctions
#         for cleanwords in cleanpunc(w).split():
#             # if cleaned is alphabet and length og words greater than 2 then proceed
#             if ((cleanwords.isalpha()) and len(cleanwords)>2):
#                 # check weather word is stop word or not
#                 if cleanwords.lower() not in stop:
#                     # If word is not stop word then append it to filtered sentence
#                     s = (sno.stem(cleanwords.lower())).encode('utf-8')
#                     filtered_sentence.append(s)
#                 else:
#                     continue
#             else:
#                 continue
#     # filtered_sentence is list contains all words of a review after preprocessing
#     # join every word in a list to get a string format of the review

#     str1 = b' '.join(filtered_sentence)
   

    

#     #str1 = ' '.join(map(bytes.decode, filtered_sentence))
#     #append all the string(cleaned reviews)to final_string
#     return str1

SPECIAL_TOKENS = {
    'quoted': 'quoted_item',
    'non-ascii': 'non_ascii_word',
    'undefined': 'something'
}

def clean(text, stem_words=True):
    import re
    from string import punctuation
    from nltk.stem import SnowballStemmer
    from nltk.corpus import stopwords
    
    def pad_str(s):
        return ' '+s+' '
    
    if pd.isnull(text):
        return ''

#    stops = set(stopwords.words("english"))
    # Clean the text, with the option to stem words.
    
    # Empty question
    
    if type(text) != str or text=='':
        return ''

    # Clean the text
    text = re.sub("\'s", " ", text) # we have cases like "Sam is" or "Sam's" (i.e. his) these two cases aren't separable, I choose to compromise are kill "'s" directly
    text = re.sub(" whats ", " what is ", text, flags=re.IGNORECASE)
    text = re.sub("\'ve", " have ", text)
    text = re.sub("can't", "can not", text)
    text = re.sub("n't", " not ", text)
    text = re.sub("i'm", "i am", text, flags=re.IGNORECASE)
    text = re.sub("\'re", " are ", text)
    text = re.sub("\'d", " would ", text)
    text = re.sub("\'ll", " will ", text)
    text = re.sub("e\.g\.", " eg ", text, flags=re.IGNORECASE)
    text = re.sub("b\.g\.", " bg ", text, flags=re.IGNORECASE)
    text = re.sub("(\d+)(kK)", " \g<1>000 ", text)
    text = re.sub("e-mail", " email ", text, flags=re.IGNORECASE)
    text = re.sub("(the[\s]+|The[\s]+)?U\.S\.A\.", " America ", text, flags=re.IGNORECASE)
    text = re.sub("(the[\s]+|The[\s]+)?United State(s)?", " America ", text, flags=re.IGNORECASE)
    text = re.sub("\(s\)", " ", text, flags=re.IGNORECASE)
    text = re.sub("[c-fC-F]\:\/", " disk ", text)
    
    # remove comma between numbers, i.e. 15,000 -> 15000
    
    text = re.sub('(?<=[0-9])\,(?=[0-9])', "", text)
    
#     # all numbers should separate from words, this is too aggressive
    
#     def pad_number(pattern):
#         matched_string = pattern.group(0)
#         return pad_str(matched_string)
#     text = re.sub('[0-9]+', pad_number, text)
    
    # add padding to punctuations and special chars, we still need them later
    
    text = re.sub('\$', " dollar ", text)
    text = re.sub('\%', " percent ", text)
    text = re.sub('\&', " and ", text)
    
#    def pad_pattern(pattern):
#        matched_string = pattern.group(0)
#       return pad_str(matched_string)
#    text = re.sub('[\!\?\@\^\+\*\/\,\~\|\`\=\:\;\.\#\\\]', pad_pattern, text) 
        
    text = re.sub('[^\x00-\x7F]+', pad_str(SPECIAL_TOKENS['non-ascii']), text) # replace non-ascii word with special word
    
    # indian dollar
    
    text = re.sub("(?<=[0-9])rs ", " rs ", text, flags=re.IGNORECASE)
    text = re.sub(" rs(?=[0-9])", " rs ", text, flags=re.IGNORECASE)
    
    # clean text rules get from : https://www.kaggle.com/currie32/the-importance-of-cleaning-text
    text = re.sub(r" (the[\s]+|The[\s]+)?US(A)? ", " America ", text)
    text = re.sub(r" UK ", " England ", text, flags=re.IGNORECASE)
    text = re.sub(r" india ", " India ", text)
    text = re.sub(r" switzerland ", " Switzerland ", text)
    text = re.sub(r" china ", " China ", text)
    text = re.sub(r" chinese ", " Chinese ", text) 
    text = re.sub(r" imrovement ", " improvement ", text, flags=re.IGNORECASE)
    text = re.sub(r" intially ", " initially ", text, flags=re.IGNORECASE)
    text = re.sub(r" quora ", " Quora ", text, flags=re.IGNORECASE)
    text = re.sub(r" dms ", " direct messages ", text, flags=re.IGNORECASE)  
    text = re.sub(r" demonitization ", " demonetization ", text, flags=re.IGNORECASE) 
    text = re.sub(r" actived ", " active ", text, flags=re.IGNORECASE)
    text = re.sub(r" kms ", " kilometers ", text, flags=re.IGNORECASE)
    text = re.sub(r" cs ", " computer science ", text, flags=re.IGNORECASE) 
    text = re.sub(r" upvote", " up vote", text, flags=re.IGNORECASE)
    text = re.sub(r" iPhone ", " phone ", text, flags=re.IGNORECASE)
    text = re.sub(r" \0rs ", " rs ", text, flags=re.IGNORECASE)
    text = re.sub(r" calender ", " calendar ", text, flags=re.IGNORECASE)
    text = re.sub(r" ios ", " operating system ", text, flags=re.IGNORECASE)
    text = re.sub(r" gps ", " GPS ", text, flags=re.IGNORECASE)
    text = re.sub(r" gst ", " GST ", text, flags=re.IGNORECASE)
    text = re.sub(r" programing ", " programming ", text, flags=re.IGNORECASE)
    text = re.sub(r" bestfriend ", " best friend ", text, flags=re.IGNORECASE)
    text = re.sub(r" dna ", " DNA ", text, flags=re.IGNORECASE)
    text = re.sub(r" III ", " 3 ", text)
    text = re.sub(r" banglore ", " Banglore ", text, flags=re.IGNORECASE)
    text = re.sub(r" J K ", " JK ", text, flags=re.IGNORECASE)
    text = re.sub(r" J\.K\. ", " JK ", text, flags=re.IGNORECASE)
    
    # replace the float numbers with a random number, it will be parsed as number afterward, and also been replaced with word "number"
    
    text = re.sub('[0-9]+\.[0-9]+', " 87 ", text)
  
    
    # Remove punctuation from text
    text = ''.join([c for c in text if c not in punctuation]).lower()
       # Return a list of words
    return text
    
df['question1'] = df['question1'].apply(clean)
df['question2'] = df['question2'].apply(clean)

a = 0 
for i in range(a,a+10):
    print(df.question1[i])
    print(df.question2[i])
    print()

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt


#***** Need to check the .fit-transform
vectorizer = TfidfVectorizer()
def cosine_sim(text1, text2):
    try:
        tfidf = vectorizer.fit_transform([text1, text2])
    except Exception:
        print(text1)
        print("-------------------")
        print(text2)
    
    return ((tfidf * tfidf.T).A)[0,1]

Tfidf_scores = []
for i in range(len(df['question1'])):
    try:
        score = cosine_sim(df['question1'][i], df['question2'][i])
    except Exception:
        print("error---")
        continue
    Tfidf_scores.append(score)

score = pd.DataFrame ( Tfidf_scores, columns = ['similarity score'])
score.head(10)

# Plot the scores
plt.figure(figsize=(12,6))
plt.style.use('ggplot')
plt.hist(Tfidf_scores, bins = 60)
plt.xlim(0,1)
plt.show()

